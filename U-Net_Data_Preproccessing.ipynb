{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".mat file and save them as png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3064 .mat files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 3064/3064 [00:31<00:00, 97.19it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import h5py\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_path = r'D:\\IIT\\Subjects\\(4606)Machine Vision\\CW\\Develo\\DataSet\\U-Net\\mat_data'\n",
    "output_img_path = r'D:\\IIT\\Subjects\\(4606)Machine Vision\\CW\\Develo\\DataSet\\U-Net\\processed\\images'\n",
    "output_mask_path = r'D:\\IIT\\Subjects\\(4606)Machine Vision\\CW\\Develo\\DataSet\\U-Net\\processed\\masks'\n",
    "\n",
    "os.makedirs(output_img_path, exist_ok=True)\n",
    "os.makedirs(output_mask_path, exist_ok=True)\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "mat_files = [f for f in os.listdir(input_path) if f.endswith('.mat')]\n",
    "print(f\"Found {len(mat_files)} .mat files\")\n",
    "\n",
    "def load_mat_file(path):\n",
    "    try:\n",
    "        # Try with scipy (non-HDF5)\n",
    "        data = scipy.io.loadmat(path)\n",
    "        cjdata = data['cjdata']\n",
    "        image = cjdata['image'][0][0]\n",
    "        mask = cjdata['tumorMask'][0][0]\n",
    "    except NotImplementedError:\n",
    "        # Use h5py for MATLAB v7.3 HDF5 files\n",
    "        with h5py.File(path, 'r') as f:\n",
    "            image = np.array(f['cjdata']['image']).T\n",
    "            mask = np.array(f['cjdata']['tumorMask']).T\n",
    "    return image, mask\n",
    "\n",
    "for file in tqdm(mat_files, desc=\"Processing\"):\n",
    "    try:\n",
    "        full_path = os.path.join(input_path, file)\n",
    "        image, mask = load_mat_file(full_path)\n",
    "\n",
    "        # Normalize image\n",
    "        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        image = image.astype(np.uint8)\n",
    "\n",
    "        # Resize\n",
    "        image_resized = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        mask_resized = cv2.resize(mask.astype(np.uint8), (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # Save\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        image_filename = os.path.join(output_img_path, base_name + \".png\")\n",
    "        mask_filename = os.path.join(output_mask_path, base_name + \".png\")\n",
    "\n",
    "        cv2.imwrite(image_filename, image_resized)\n",
    "        cv2.imwrite(mask_filename, mask_resized * 255)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully split into train, val, and test sets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Update this to your actual base path\n",
    "base_dir = r'D:\\IIT\\Subjects\\(4606)Machine Vision\\CW\\Develo\\DataSet\\U-Net\\processed'\n",
    "images_dir = os.path.join(base_dir, 'images')\n",
    "masks_dir = os.path.join(base_dir, 'masks')\n",
    "\n",
    "# Output path\n",
    "split_base_dir = os.path.join(base_dir, 'split')\n",
    "splits = ['train', 'val', 'test']\n",
    "split_ratio = {'train': 0.7, 'val': 0.2, 'test': 0.1}\n",
    "\n",
    "# Create necessary directories\n",
    "for split in splits:\n",
    "    os.makedirs(os.path.join(split_base_dir, split, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split_base_dir, split, 'masks'), exist_ok=True)\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith('.png')]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Calculate split indexes\n",
    "total = len(image_files)\n",
    "train_end = int(split_ratio['train'] * total)\n",
    "val_end = train_end + int(split_ratio['val'] * total)\n",
    "\n",
    "split_files = {\n",
    "    'train': image_files[:train_end],\n",
    "    'val': image_files[train_end:val_end],\n",
    "    'test': image_files[val_end:]\n",
    "}\n",
    "\n",
    "# Copy files\n",
    "for split, files in split_files.items():\n",
    "    for file in files:\n",
    "        shutil.copy(os.path.join(images_dir, file), os.path.join(split_base_dir, split, 'images', file))\n",
    "        shutil.copy(os.path.join(masks_dir, file), os.path.join(split_base_dir, split, 'masks', file))\n",
    "\n",
    "print(\"✅ Data successfully split into train, val, and test sets.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TenserFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
